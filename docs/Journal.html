<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Journal</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Sophia Site</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Journal.html">Journal</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Journal</h1>

</div>


<p>This page will contain all the assignments you submit for the class.</p>
<div id="instructions-for-all-assignments" class="section level3">
<h3>Instructions for all assignments</h3>
<p>I want you to submit your assignment as a PDF, so I can keep a record of what the code looked like that day. I also want you to include your answers on your personal GitHub website. This will be good practice for editing your website and it will help you produce something you can keep after the class is over.</p>
<ol style="list-style-type: decimal">
<li><p>Download the Assignment1.Rmd file from Canvas. You can use this as a template for writing your answers. It’s the same as what you can see on my website in the Assignments tab. Once we’re done with this I’ll edit the text on the website to include the solutions.</p></li>
<li><p>On RStudio, open a new R script in RStudio (File &gt; New File &gt; R Script). This is where you can test out your R code. You’ll write your R commands and draw plots here.</p></li>
<li><p>Once you have finalized your code, copy and paste your results into this template (Assignment 1.Rmd). For example, if you produced a plot as the solution to one of the problems, you can copy and paste the R code in R markdown by using the <code>``{r} ```</code> command. Answer the questions in full sentences and Save.</p></li>
<li><p>Produce a PDF file with your answers. To do this, knit to PDF (use Knit button at the top of RStudio), locate the PDF file in your docs folder (it’s in the same folder as the Rproj), and submit that on on Canvas in Assignment 1.</p></li>
<li><p>Build Website, go to GitHub desktop, commit and push. Now your solutions should be on your website as well.</p></li>
</ol>
</div>
<div id="assignment-1" class="section level1">
<h1>Assignment 1</h1>
<p><strong>Collaborators: Natalie Yang. </strong></p>
<p>This assignment is due on Canvas on Monday 9/20 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<div id="problem-1" class="section level3">
<h3>Problem 1</h3>
<p>Install the datasets package on the console below using <code>install.packages(&quot;datasets&quot;)</code>. Now load the library.</p>
<pre class="r"><code>library(datasets)</code></pre>
<p>Load the USArrests dataset and rename it <code>dat</code>. Note that this dataset comes with R, in the package datasets, so there’s no need to load data from your computer. Why is it useful to rename the dataset?</p>
<pre class="r"><code>dat &lt;- USArrests</code></pre>
<div id="its-useful-to-rename-the-dataset-so-you-know-can-keep-track-of-which-dataset-is-which---it-can-stick-in-your-mind-more-if-you-rename-it.-also-when-youre-altering-data-its-best-to-keep-track-of-the-different-versions-are-which-ie-which-datasets-are-untouched-etc.-lastly-i-wouldnt-want-to-alter-a-base-r-package-dataset-and-then-save-it-to-my-workspace-and-have-that-alter-things-in-the-future." class="section level4">
<h4>It’s useful to rename the dataset so you know can keep track of which dataset is which - it can stick in your mind more if you rename it. Also, when you’re altering data, it’s best to keep track of the different versions are which (ie which datasets are untouched, etc). Lastly, I wouldn’t want to alter a Base R package dataset, and then save it to my workspace, and have that alter things in the future.</h4>
</div>
</div>
<div id="problem-2" class="section level3">
<h3>Problem 2</h3>
<p>Use this command to make the state names into a new variable called State.</p>
<pre class="r"><code>dat$state &lt;- tolower(rownames(USArrests))</code></pre>
<p>This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.</p>
<p>List the variables contained in the dataset <code>USArrests</code>.</p>
<pre class="r"><code>colnames(dat)</code></pre>
<pre><code>## [1] &quot;Murder&quot;   &quot;Assault&quot;  &quot;UrbanPop&quot; &quot;Rape&quot;</code></pre>
<div id="the-output-is-1-murder-assault-urbanpop-rape-state" class="section level4">
<h4>The output is: [1] “Murder” “Assault” “UrbanPop” “Rape” “state”</h4>
</div>
</div>
<div id="problem-3" class="section level3">
<h3>Problem 3</h3>
<p>What type of variable (from the DVB chapter) is <code>Murder</code>?</p>
<p>Answer: A quantitative variable.</p>
<p>What R Type of variable is it?</p>
<p>Answer: Numeric (class(dat$Murder) returns numeric)</p>
</div>
<div id="problem-4" class="section level3">
<h3>Problem 4</h3>
<p>What information is contained in this dataset, in general? What do the numbers mean?</p>
<p>Answer: This dataset contains information on Murder, Assault, and Rape per 100,000 residents, by state for all 50 states in the United States.</p>
</div>
<div id="problem-5" class="section level3">
<h3>Problem 5</h3>
<p>Draw a histogram of <code>Murder</code> with proper labels and title.</p>
<pre class="r"><code>hist(dat$Murder, 
     main = &quot;Histogram of Murders&quot;, 
     xlim = c(0, 20),
     ylim = c(0, 13),
     xlab = &quot;Number of Murders&quot;, 
     ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="problem-6" class="section level3">
<h3>Problem 6</h3>
<p>Please summarize <code>Murder</code> quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?</p>
<pre class="r"><code>mean(dat$Murder)</code></pre>
<pre><code>## [1] 7.788</code></pre>
<pre class="r"><code>median(dat$Murder)</code></pre>
<pre><code>## [1] 7.25</code></pre>
<pre class="r"><code>summary(dat$Murder)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.800   4.075   7.250   7.788  11.250  17.400</code></pre>
<div id="mean-is-the-average-amount-of-murders-in-all-50-states-while-median-is-the-middle-state-murder-level-in-the-dataset.-the-1st-quartile-shows-us-that-the-lowest-25-state-murder-rates-are-under-4.075.-the-3rd-quartile-shows-us-that-for-the-50.1-75-of-states-which-is-the-block-right-above-the-median.-we-dont-need-the-2nd-quartile-because-we-have-the-median-to-know-that-the-25.1-50-of-states-fall-between-that-number-and-the-1st-quartile.-we-are-given-the-max-as-well-which-is-technically-the-4th-quartile-and-that-alongside-the-3rd-quartile-amount-gives-us-all-the-information-we-need-about-distribution-of-murder-rate-in-the-dataset.-the-mean-is-also-greater-than-the-median-so-the-dataset-is-positively-skewed." class="section level4">
<h4>Mean is the average amount of Murders in all 50 states, while median is the middle state Murder level in the dataset. The 1st quartile shows us that the lowest 25% state Murder rates are under 4.075. The 3rd quartile shows us that for the 50.1-75% of states, which is the block right above the median. We don’t need the 2nd quartile because we have the Median to know that the 25.1-50% of states fall between that number and the 1st quartile. We are given the max as well, which is technically the 4th quartile, and that alongside the 3rd quartile amount gives us all the information we need about distribution of Murder rate in the dataset. The mean is also greater than the median, so the dataset is positively skewed.</h4>
</div>
</div>
<div id="problem-7" class="section level3">
<h3>Problem 7</h3>
<p>Repeat the same steps you followed for <code>Murder</code>, for the variables <code>Assault</code> and <code>Rape</code>. Now plot all three histograms together. You can do this by using the command <code>par(mfrow=c(3,1))</code> and then plotting each of the three.</p>
<pre class="r"><code>par(mfrow=c(3, 1))

hist(dat$Assault, 
     main = &quot;Histogram of Assaults&quot;, 
     xlim = c(0, 355),
     ylim = c(0, 15),
     xlab = &quot;Number of Assaults&quot;, 
     ylab = &quot;Frequency&quot;)

hist(dat$Murder, 
     main = &quot;Histogram of Murders&quot;, 
     xlim = c(0, 20),
     ylim = c(0, 13),
     xlab = &quot;Number of Murders&quot;, 
     ylab = &quot;Frequency&quot;)

hist(dat$Rape, 
     main = &quot;Histogram of Rapes&quot;, 
     xlim = c(0, 52),
     ylim = c(0, 15),
     xlab = &quot;Number of Rapes&quot;, 
     ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-7-1.png" width="480" /></p>
<p>What does the command par do, in your own words (you can look this up by asking R <code>?par</code>)?</p>
<p>Answer: Par splits up our screen so we can see more than one figure in one viewing. In the example above, we used par to split the screen into three horizontal chunks. By changing the second number in the par function, we could also bisect the screen vertically.</p>
<p>What can you learn from plotting the histograms together?</p>
<p>Answer: You can compare frequencies, and you can also see how some crimes (such as Assaults) are committed more than others (e.g. Murders).</p>
</div>
<div id="problem-8" class="section level3">
<h3>Problem 8</h3>
<p>In the console below (not in text), type <code>install.packages(&quot;maps&quot;)</code> and press Enter, and then type <code>install.packages(&quot;ggplot2&quot;)</code> and press Enter. This will install the packages so you can load the libraries.</p>
<p>Run this code:</p>
<pre class="r"><code>library(&#39;maps&#39;) 
library(&#39;ggplot2&#39;) 

ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data(&quot;state&quot;)) + 
  expand_limits(x=map_data(&quot;state&quot;)$long, y=map_data(&quot;state&quot;)$lat)</code></pre>
<p>What does this code do? Explain what each line is doing.</p>
<p>Answer: This code shows the murder rates graphically. With the entire contiguous US being shown on a map, the code shades states on a light-dark scale based on how high their Murder rate (per 100,000 residents) are. States with lower murder rates are shaded darker, and vice versa for higher ones. We can see states in the PNW and NE regions have lower Murder rates than states in the SE visually with this map.</p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
</div>
<div id="assignment-2" class="section level1">
<h1>Assignment 2</h1>
<p>Instructions: Copy your code, paste it into a Word document, and turn it into Canvas. You can turn in a .docx or .pdf file. Show any EDA (graphical or non-graphical) you have used to come to this conclusion.</p>
<p><strong>Collaborators: Natalie Yang. </strong></p>
<p>Instructions: Copy your code, paste it into a Word document, and turn it into Canvas. You can turn in a .docx or .pdf file. Show any EDA (graphical or non-graphical) you have used to come to this conclusion.</p>
<div id="set-your-working-directory-to-the-folder-where-you-downloaded-the-data." class="section level2">
<h2>Set your working directory to the folder where you downloaded the data.</h2>
</div>
<div id="read-the-data" class="section level2">
<h2>Read the data</h2>
<pre class="r"><code>library(readr)</code></pre>
<pre><code>## Warning: package &#39;readr&#39; was built under R version 3.6.2</code></pre>
<pre class="r"><code>dat &lt;- read_csv(&quot;dat.nsduh.small.1.csv&quot;)</code></pre>
<pre><code>## Rows: 171 Columns: 7</code></pre>
<pre><code>## ── Column specification ───────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## dbl (7): mjage, cigage, iralcage, age2, sexatract, speakengl, irsex</code></pre>
<pre><code>## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div id="what-are-the-dimensions-of-the-dataset" class="section level2">
<h2>What are the dimensions of the dataset?</h2>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 171   7</code></pre>
<p>The dimensions are 171 rows by 7 columns</p>
</div>
<div id="problem-2-variables" class="section level2">
<h2>Problem 2: Variables</h2>
<div id="describe-the-variables-in-the-dataset." class="section level3">
<h3>Describe the variables in the dataset.</h3>
<div id="the-variables-are-all-numeric.-they-represent-different-number-ranges-which-account-for-different-meanings.for-example-the-age2-variable-represents-the-respondents-age.-in-some-buckets-only-the-exact-age-is-contain-ie-1-represents-the-age-12-but-in-others-it-represents-a-range-eg-13-represents-ages-26-29." class="section level4">
<h4>The variables are all numeric. They represent different number ranges, which account for different meanings.For example, the age2 variable represents the respondents age. In some buckets, only the exact age is contain (ie 1 represents the age 12), but in others it represents a range (eg 13 represents ages 26-29).</h4>
</div>
</div>
<div id="what-is-this-dataset-about-who-collected-the-data-what-kind-of-sample-is-it-and-what-was-the-purpose-of-generating-the-data" class="section level3">
<h3>What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data?</h3>
<div id="this-data-set-is-from-the-national-survey-of-drug-use-in-2019.-it-looks-into-when-respondents-first-started-using-drugsalcoholnicotine-even-if-its-before-the-legal-age.-the-nsduh-collected-the-data-and-it-seems-to-be-a-random-sample-from-a-large-range-of-ages.-this-data-is-meant-to-reflect-drugalcoholetc-use-across-the-whole-country." class="section level4">
<h4>This data set is from the National Survey of Drug Use in 2019. It looks into when respondents first started using drugs/alcohol/nicotine, even if it’s before the legal age. The NSDUH collected the data, and it seems to be a random sample from a large range of ages. This data is meant to reflect drug/alcohol/etc use across the whole country.</h4>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;mjage&quot;     &quot;cigage&quot;    &quot;iralcage&quot;  &quot;age2&quot;      &quot;sexatract&quot; &quot;speakengl&quot;
## [7] &quot;irsex&quot;</code></pre>
<p>The variables are: mjage, cigage, iralcage, age2, sexatract, speakengl, and irsex</p>
</div>
</div>
</div>
<div id="problem-3-age-and-gender" class="section level2">
<h2>Problem 3: Age and gender</h2>
<div id="what-is-the-age-distribution-of-the-sample-like-make-sure-you-read-the-codebook-to-know-what-the-variable-values-mean." class="section level3">
<h3>What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.</h3>
<pre class="r"><code>hist(dat$age2, 
     main = &quot;Histogram of Age&quot;,
     xlim = c(0, 20),
     ylim = c(0, 120),
     xlab = &quot;Quantity in Each Age Bucket&quot;, 
     ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<div id="the-age-frequency-obciously-isnt-fully-representative-of-the-us-population-because-it-doesnt-have-respondents-below-the-age-of-12." class="section level4">
<h4>The age frequency obciously isn’t fully representative of the US population, because it doesn’t have respondents below the age of 12.</h4>
</div>
</div>
<div id="is-the-sample-balanced-in-terms-of-gender-if-not-are-there-more-females-or-males" class="section level3">
<h3>Is the sample balanced in terms of gender? If not, are there more females or males?</h3>
<pre class="r"><code>sum(dat$irsex[dat$irsex == 2])</code></pre>
<pre><code>## [1] 160</code></pre>
<pre class="r"><code>sum(dat$irsex)</code></pre>
<pre><code>## [1] 251</code></pre>
<p>160 females, 251 respondents in total</p>
<div id="this-sample-isnt-balanced-in-terms-of-gender-because-there-are-69-more-females-than-males.-this-is-not-representative-of-the-us-population-where-gender-is-mostly-balanced." class="section level4">
<h4>This sample isn’t balanced in terms of gender because there are 69 more females than males. This is not representative of the US population, where gender is mostly balanced.</h4>
</div>
</div>
</div>
<div id="problem-4-substance-use" class="section level2">
<h2>Problem 4: Substance use</h2>
<div id="for-which-of-the-three-substances-included-in-the-dataset-marijuana-alcohol-and-cigarettes-do-individuals-tend-to-use-the-substance-earlier" class="section level4">
<h4>For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?</h4>
<pre class="r"><code>dat$iralcage[dat$iralcage == 5]</code></pre>
<pre><code>## [1] 5 5</code></pre>
<pre class="r"><code>dat$cigage[dat$cigage == 10]</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code>dat$mjage[dat$mjage == 7]</code></pre>
<pre><code>## [1] 7</code></pre>
<p>There is only one user in the earliest bucket for marijuana and cigarette use. There are two for alcohol use. I am deducing that individuals tend to use alcohol earlier.</p>
</div>
</div>
<div id="problem-5-sexual-attraction" class="section level2">
<h2>Problem 5: Sexual attraction</h2>
<div id="what-does-the-distribution-of-sexual-attraction-look-like-is-this-what-you-expected" class="section level3">
<h3>What does the distribution of sexual attraction look like? Is this what you expected?</h3>
<pre class="r"><code>dat$sex.attract &lt;- dat$sexatract
dat$sex.attract[dat$sex.attract == 85 | dat$sex.attract == 94 | dat$sex.attract == 97 |
                  dat$sex.attract == 98 | dat$sex.attract == 99 ] &lt;- NA

hist(dat$sex.attract, 
     main = &quot;Histogram of Sexual Attraction&quot;,
     xlab = &quot;Quantity in Each Age Bucket&quot;, 
     ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-15-1.png" width="672" /> Most people identify as heterosexual, which is what I expected.</p>
</div>
<div id="what-is-the-distribution-of-sexual-attraction-by-gender" class="section level3">
<h3>What is the distribution of sexual attraction by gender?</h3>
<pre class="r"><code>tab.sexgender &lt;- table(dat$sex.attract, dat$irsex)
barplot(tab.sexgender,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Gender&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.sexgender),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-16-1.png" width="672" /> More males identify as straight than females.</p>
</div>
</div>
<div id="problem-6-english-speaking" class="section level2">
<h2>Problem 6: English speaking</h2>
<div id="what-does-the-distribution-of-english-speaking-look-like-in-the-sample-is-this-what-you-might-expect-for-a-random-sample-of-the-us-population" class="section level3">
<h3>What does the distribution of English speaking look like in the sample? Is this what you might expect for a random sample of the US population?</h3>
<pre class="r"><code>hist(dat$speakengl, 
     main = &quot;Histogram of English Speaking&quot;,
     xlim = c(1,3),
     ylim = c(0, 200),
     xlab = &quot;Quantity in Each Age Bucket&quot;, 
     ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-17-1.png" width="672" /> Mostly everyone is an English speaker, and speaks very well/well, which is what I expected, as this is a national sample coming from the United States, and the official language is English. It would be interesting to look at how many people are native English speakers in the future.</p>
</div>
<div id="are-there-more-english-speaker-females-or-males" class="section level3">
<h3>Are there more English speaker females or males?</h3>
<div id="in-this-im-using-values-1-3-to-count-as-speaking-english" class="section level4">
<h4>(in this, I’m using values 1-3 to count as speaking English)</h4>
<pre class="r"><code>sum(dat$irsex[dat$irsex == 1 &amp; (dat$speakengl == 1 | dat$speakengl == 2 | dat$speakengl == 3)])</code></pre>
<pre><code>## [1] 91</code></pre>
<pre class="r"><code>sum(dat$irsex[dat$irsex == 2 &amp; (dat$speakengl == 1 | dat$speakengl == 2 | dat$speakengl == 3)])</code></pre>
<pre><code>## [1] 160</code></pre>
<p>91 English speakers are male, and 160 are females. All respondents fall into a English-speaking bucket, and so with the unbalanced gender we saw earlier, there are more female English speakers than male.</p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
</div>
</div>
</div>
<div id="assignment-3" class="section level1">
<h1>Assignment 3</h1>
<p><strong>Collaborators: Natalie Yang</strong>.</p>
<p>This assignment is due on Canvas on Wednesday 10/27/2021 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<p>Submit your responses as either an HTML file or a PDF file on Canvas. Also, please upload it to your website.</p>
<p>Save the file (found on Canvas) crime_simple.txt to the same folder as this file (your Rmd file for Assignment 3).</p>
<p>Load the data.</p>
<pre class="r"><code>## setwd(&quot;~/Desktop/senior year/crim 250/assignments/assignment 3&quot;)
## install.packages(&quot;ggpubr&quot;)
library(readr)
library(knitr)
library(ggpubr)</code></pre>
<pre><code>## Warning: package &#39;ggpubr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.6.2</code></pre>
<pre class="r"><code>dat.crime &lt;- read_delim(&quot;crime_simple.txt&quot;, delim = &quot;\t&quot;)</code></pre>
<pre><code>## Rows: 47 Columns: 14</code></pre>
<pre><code>## ── Column specification ───────────────────────────────────────────────────
## Delimiter: &quot;\t&quot;
## dbl (14): R, Age, S, Ed, Ex0, Ex1, LF, M, N, NW, U1, U2, W, X</code></pre>
<pre><code>## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<p>This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given.</p>
<p>Here is the codebook:</p>
<p>R: Crime rate: # of offenses reported to police per million population</p>
<p>Age: The number of males of age 14-24 per 1000 population</p>
<p>S: Indicator variable for Southern states (0 = No, 1 = Yes)</p>
<p>Ed: Mean of years of schooling x 10 for persons of age 25 or older</p>
<p>Ex0: 1960 per capita expenditure on police by state and local government</p>
<p>Ex1: 1959 per capita expenditure on police by state and local government</p>
<p>LF: Labor force participation rate per 1000 civilian urban males age 14-24</p>
<p>M: The number of males per 1000 females</p>
<p>N: State population size in hundred thousands</p>
<p>NW: The number of non-whites per 1000 population</p>
<p>U1: Unemployment rate of urban males per 1000 of age 14-24</p>
<p>U2: Unemployment rate of urban males per 1000 of age 35-39</p>
<p>W: Median value of transferable goods and assets or family income in tens of $</p>
<p>X: The number of families per 1000 earning below 1/2 the median income</p>
<p>We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related.</p>
<ol style="list-style-type: decimal">
<li>How many observations are there in the dataset? To what does each observation correspond?</li>
</ol>
<pre class="r"><code>dim(dat.crime)</code></pre>
<pre><code>## [1] 47 14</code></pre>
<p>The number of rows (47) correspond to the states in the survey, and the 14 columns relate to each letter in the codebook for these answers. So, the 5th row, column U1 would show the Unemployment rate of urban males per 1000 of age 14-24 in that state.</p>
<ol start="2" style="list-style-type: decimal">
<li>Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?</li>
</ol>
<pre class="r"><code>cor(dat.crime$Ed, dat.crime$U2,  method = &quot;pearson&quot;, use = &quot;complete.obs&quot;)</code></pre>
<pre><code>## [1] -0.2156816</code></pre>
<pre class="r"><code>ggscatter(dat.crime, x = &quot;Ed&quot;, y = &quot;U2&quot;, 
          add = &quot;reg.line&quot;, cor.method = &quot;pearson&quot;,
          xlab = &quot;Mean of years of schooling&quot;, ylab = &quot;Unemployment rate&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-21-1.png" width="576" /></p>
<p>The correlation function shows a small negative correlation between mean years of school and education. So, as mean years of school increases, the unemployment level decreases. The scatter plot visualizes this relationship, and the regline shows that it is a small level of correlation.</p>
<ol start="3" style="list-style-type: decimal">
<li>Regress reported crime rate (y) on average education (x) and call this linear model <code>crime.lm</code> and write the summary of the regression by using this code, which makes it look a little nicer <code>{r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2)</code>.</li>
</ol>
<pre class="r"><code>crime.lm &lt;- lm(R ~ Ed, data = dat.crime)
summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = R ~ Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -27.3967    51.8104  -0.529   0.5996  
## Ed            1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)</li>
</ol>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, pch = 16, cex = 1.3, frame = F,   
     main = &quot;Crime Rate and Education Relationship&quot;,
     xlab = &quot;Mean of years of schooling x 10 for persons of age 25 or older&quot;,
     ylab = &quot;# of offenses reported to police per million population&quot;)

abline(crime.lm, h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=1)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-23-2.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=3)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-23-3.png" width="672" /></p>
<pre class="r"><code>plot(crime.lm, which=2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-23-4.png" width="672" /></p>
<p><strong>The linearity assumption is satisfied because the scatterplot ab-line is straight, and the red line from the Residuals vs Fitted graph is flat, which shows us that there is no discernible non-linear trend to the residuals. The independence assumption is satisfied because there are no patterns in the scatter when graphing against Ed or the residuals. The scale-location plot shows us a pretty flat line, which means the errors have constant variance, and the assumption is satisfied. The normality assumption is satisfied, because the QQ plot graph has its residuals mostly following the line, which means there’s a normal distribution (follows the population).</strong></p>
<ol start="5" style="list-style-type: decimal">
<li>Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?</li>
</ol>
<p><strong>I am using the summary(crime.lm) output from problem 3 to guide my answers. The relationship between reported crime and average education is statistically significant because the p-value is less than .05 (and the software marks such). The p-value is 0.0269. The standard error is 0.4878, which is less than 1.96. The coefficient of the slope is -27.3967. When a relationship is statistically significant, we can reject the null hypothesis at 95% confidence.</strong></p>
<ol start="6" style="list-style-type: decimal">
<li>How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?</li>
</ol>
<p><strong>Crime and education are tied, because for each unit increase in average education, the crime rate/million people increases by 1.1161 units. One would assume that a population with more education would have less crime in it, but that is not the case that this regression shows. </strong></p>
<ol start="7" style="list-style-type: decimal">
<li>Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?</li>
</ol>
<p><strong>This conclusion cannot be drawn. The wording in the code book does not distinguish between crime rate and number of crimes reported. Also, our regression is way to simple to conclude that just education increases crime reported - it definitely has omitted variable bias in it. This data is not a time-series - we aren’t looking at the sample location over periods of time as education has changed - how would we know that there are no differences in crime based on state? </strong></p>
<p><span class="math display">\[\\[2in]\]</span></p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
<div id="assignment-4" class="section level1">
<h1>Assignment 4</h1>
<pre class="r"><code>## install.packages(&quot;tidyverse&quot;)
library(tidyverse)</code></pre>
<pre><code>## Warning: package &#39;tidyverse&#39; was built under R version 3.6.2</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ tibble  3.1.5     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.4     ✓ stringr 1.4.0
## ✓ purrr   0.3.4     ✓ forcats 0.5.1</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;purrr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;forcats&#39; was built under R version 3.6.2</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<p><strong>install/load in tidyverse package (what we need for ggplot functions)</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-25-1.png" width="672" /> <strong>don’t need to load in mpg dataset because it’s base R. This function starts with a base map, then each argument adds another layer to it - such as geom_point() adding scatters to it, thus creating a scatter plot.</strong></p>
<pre class="r"><code>ggplot(data = mpg) ## blank template to plot on</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code>dim (mpg) ## [1] 234  11</code></pre>
<pre><code>## [1] 234  11</code></pre>
<pre class="r"><code>## ?mpg - drv shows us the type of drive train, where f = front-wheel drive, r = rear wheel drive, 4 = 4wd
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = hwy, y = cyl))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-26-2.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = class, y = drv))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-26-3.png" width="672" /></p>
<pre class="r"><code>## this isn&#39;t really useful because it shows us the type of car vs the type of drive (front wheel/4 wheel/etc), and each different type of car has a different type of drive so there wouldn&#39;t be any &quot;relationship&quot; to see because it&#39;s all one set thing</code></pre>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = &quot;blue&quot;))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code>## ?mpg</code></pre>
<p><strong>There is a missing parenthesis before color so it’s not being put in correctly to the ggplot function when it’s set manually/by name.</strong></p>
<p><strong>Categorical variables are ones such as type of car/transmission/model name, while variables such as miles per gallon are discrete/continuous.</strong></p>
<pre class="r"><code>## ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, 
                           color = hwy, size = cty, shape = displ))</code></pre>
<pre><code>## mapping: x = ~displ, y = ~hwy, colour = ~hwy, size = ~cty, shape = ~displ 
## geom_point: na.rm = FALSE
## stat_identity: na.rm = FALSE
## position_identity</code></pre>
<p><strong>We get errors because continuous functions can’t be used for these - how is one supposed to set a color based on a variable when there aren’t even set variables?</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, 
                           color = class, shape = class, size = class))</code></pre>
<pre><code>## Warning: Using size for a discrete variable is not advised.</code></pre>
<pre><code>## Warning: The shape palette can deal with a maximum of 6 discrete values
## because more than 6 becomes difficult to discriminate; you have 7.
## Consider specifying shapes manually if you must have them.</code></pre>
<pre><code>## Warning: Removed 62 rows containing missing values (geom_point).</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code>## ?geom_point</code></pre>
<p><strong>Everything looks all messy and not-uniform because every different type of car has a different size/shape/color.</strong></p>
<p><strong>stroke adjusts the thickness of the border for shapes that can take on different colors both inside and outside</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, colour = displ &lt; 5))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p><strong>This changes the color of the scatter dot based off of the value for displacement. So, andy engine with displacement of 5 litres is a different color</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ cty, nrow = 2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-31-1.png" width="672" /> <strong>The subsets of data show up in an interesting pattern because they’re not set with each “category” as with a discrete variable</strong></p>
<p><strong>3.5.2 - These blanks represent the categories in which drive/class do not overlap so there is nothing to plot here in facet</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ .)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(. ~ cyl)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-32-2.png" width="672" /></p>
<p><strong>The . makes it so the rows/columns are not faceted</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<pre class="r"><code>##?facet_wrap</code></pre>
<p><strong>Faceting helps clearly split up each “type” into a different graph without the data all overlaying eachother. However, a large dataset with many different types would make many graphs which could get confusing.</strong></p>
<p><strong>nrow/ncol show the number of rows and columns. Facet grid doesn’t have this because the formula in it should contain two variables, and those variables’ overlap is where there are different graphs.</strong></p>
<p><strong>3.5.6 - it’s easier to visualize the unique variable with all the different subtypes as the rows then having a many short/clustered columns - this creates a more aesthetically appealing graph</strong></p>
<p><strong>3.6.1 - I would use geom_point for a line graph, and geom_smooth for the rest of the graphs listed. </strong></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + 
  geom_point() + 
  geom_smooth(se = FALSE)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-34-1.png" width="672" /> <strong>This tracks with what I expected because the se default is TRUE, so with it FALSE there is no smoothing occurin and so it looks like a mixed line/scatter chart separated by category.</strong></p>
<p><strong>3.6.3 - This tells us whether or not to show the legend in our graph. When it’s false, there is no legend. I think it was used earlier in the chapter because it distinguishes which variable is which, and so we know what each color represents.</strong></p>
<p><strong>3.6.4 - As mentioned in 3.5.2, the se function tells us whether or not smoothing is in effect. The default is TRUE.</strong></p>
<p><strong>3.6.5 - No, these graphs won’t look any different because everything specified in the second graph is the default settings for the smooth/point functions.</strong></p>
<pre class="r"><code>?stat_summary</code></pre>
<p><strong>3.7.2 - geom_bar() makes the height of the bar proportional to the number of cases in each group. geom_col() uses stat_identity() and leaves the data as is.</strong></p>
<p><strong>3.7.3 -</strong></p>
<p><strong>3.7.4 - </strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = after_stat(prop)))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = after_stat(prop)))</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-36-2.png" width="672" /> <strong>group =1 tells us how to group all the different variables. These two graphs have issues because they’re not grouped at all. The first graph has no color in it because it needs the grouping variable to do that. The second has many colors because each category is grouped by default, so each category is grouped within itself additionally.</strong></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + 
  geom_point()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p><strong>Right now, values are being rounded and many points overlap (so it looks like the observations aren’t all being plotted). This could be improved with position = “jitter”, which adds random noise to each variable, and helps solve the overplotting issue shown here. </strong></p>
<p><strong>3.8.2 - different widths/heights can be called into jittering. Also, position adjustments can be made, as well as statistical transformations. </strong></p>
<p><strong>3.8.3 - Geom count tells us how many observations are at each location. This doesn’t solve an overplotting issue (visually), but helps describe what’s occurring in the graph. Geom jitter visually demonstrates overplotting by adding the randomness. </strong></p>
<pre class="r"><code>bar &lt;- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)

bar + coord_polar()</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<pre class="r"><code>## ?labs</code></pre>
<p><strong>3.9.2 - labs makes sure axis/legend labels always display the full variable name. </strong></p>
<p><strong>3.9.3 - coord map simply maps the information, while quickmap sets the aspect ratio correctly in addition to mapping, which is very important for geographic information.</strong></p>
<p><strong>3.9.4 - This shows us the relationship between city/highway miles per gallon with respect to different types of cars. Coord_fixed fixes the aspect ratio, and makes sure that one unit on the x-axis is the same length as one unit on the y-axis (with the default setting used here). Geom_abline adds a reference line to the plot - the default setting is used here, so we’re not basing the abline off of the data in the scatter.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  labs(
    x = &quot;Engine displacement (L)&quot;,
    y = &quot;Highway fuel economy (mpg)&quot;,
    colour = &quot;Car type&quot;
  )</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth() +
  labs(
    x = &quot;Engine displacement (L)&quot;,
    y = &quot;Highway fuel economy (mpg)&quot;,
    colour = &quot;Car type&quot;
  )</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(se = FALSE) +
   labs(
    x = &quot;Engine displacement (L)&quot;,
    y = &quot;Highway fuel economy (mpg)&quot;,
    title = &quot;Highway fuel Economy and Engine Displacement&quot;,
    subtitle = &quot;(MPG vs L)&quot;,
    colour = &quot;Car type&quot;
  )</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<pre class="r"><code>label &lt;- mpg %&gt;%
  summarise(
    displ = max(displ),
    hwy = max(hwy),
    label = &quot;Increasing engine size is \nrelated to decreasing fuel economy.&quot;
  )

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_text(aes(label = label), data = label, vjust = &quot;top&quot;, hjust = &quot;right&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<pre class="r"><code>## adds a single label to the plot</code></pre>
<pre class="r"><code>## ?annotate</code></pre>
<p><strong>adds small annotations from vectors - the variables aren’t from the data frame, so a tibble isn’t necessary. This is especially sueful for adding small annotations or if you already have vectors and don’t want to make a dataframe.</strong></p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
<div id="exam-1" class="section level1">
<h1>Exam 1</h1>
<div id="instructions" class="section level2">
<h2>Instructions</h2>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (fatal-police-shootings-data.csv) onto that folder, and save your Exam 1.Rmd file in the same folder.</p></li>
<li><p>Download the README.md file. This is the codebook.</p></li>
<li><p>Load the data into an R data frame.</p></li>
</ol>
<pre class="r"><code>dat &lt;- read_csv(&quot;fatal-police-shootings-data.csv&quot;)</code></pre>
<pre><code>## Rows: 6594 Columns: 17</code></pre>
<pre><code>## ── Column specification ───────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr  (9): name, manner_of_death, armed, gender, race, city, state, thre...
## dbl  (4): id, age, longitude, latitude
## lgl  (3): signs_of_mental_illness, body_camera, is_geocoding_exact
## date (1): date</code></pre>
<pre><code>## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div id="problem-1-10-points" class="section level2">
<h2>Problem 1 (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>Describe the dataset. This is the source: <a href="https://github.com/washingtonpost/data-police-shootings" class="uri">https://github.com/washingtonpost/data-police-shootings</a> . Write two sentences (max.) about this.</li>
</ol>
<div id="the-dataset-compiled-by-washington-post-tracks-fatal-civilian-shootings-in-the-united-states-by-an-officer-in-the-line-of-duty-since-january-1-2015.-it-tracks-more-than-a-dozen-details-e.g.race-of-the-victim-if-they-were-having-a-mental-health-crisis-which-are-not-available-in-cdcfbi-records-and-those-records-are-incomplete---the-database-is-updated-regularly-with-new-detailsshootings." class="section level4">
<h4>The dataset (compiled by Washington Post) tracks fatal civilian shootings in the United States by an officer in the line of duty since January 1, 2015. It tracks more than a dozen details, (e.g.race of the victim, if they were having a mental health crisis), which are not available in CDC/FBI records, and those records are incomplete - the database is updated regularly with new details/shootings.</h4>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many observations are there in the data frame?</li>
</ol>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 6594   17</code></pre>
</div>
<div id="there-are-6594-observations-in-the-data-frame" class="section level4">
<h4>There are 6,594 observations in the data frame</h4>
<ol start="3" style="list-style-type: lower-alpha">
<li>Look at the names of the variables in the data frame. Describe what “body_camera”, “flee”, and “armed” represent, according to the codebook. Again, only write one sentence (max) per variable.</li>
</ol>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>##  [1] &quot;id&quot;                      &quot;name&quot;                   
##  [3] &quot;date&quot;                    &quot;manner_of_death&quot;        
##  [5] &quot;armed&quot;                   &quot;age&quot;                    
##  [7] &quot;gender&quot;                  &quot;race&quot;                   
##  [9] &quot;city&quot;                    &quot;state&quot;                  
## [11] &quot;signs_of_mental_illness&quot; &quot;threat_level&quot;           
## [13] &quot;flee&quot;                    &quot;body_camera&quot;            
## [15] &quot;longitude&quot;               &quot;latitude&quot;               
## [17] &quot;is_geocoding_exact&quot;</code></pre>
</div>
<div id="body_camera-denotes-whether-or-not-the-officer-who-killed-the-civilian-was-wearing-a-body-camera-at-some-point-during-the-incident.-flee-tells-us-if-the-victim-was-moving-away-from-officers-and-if-so---by-what-means.-the-armed-variable-tells-us-if-the-victim-was-armed-with-some-sort-of-implement-that-a-police-officer-believed-could-inflict-harm." class="section level4">
<h4>“body_camera” denotes whether or not the officer who killed the civilian was wearing a body camera at some point during the incident. “flee” tells us if the victim was moving away from officers, and if so - by what means. The “armed” variable tells us if the victim was armed with some sort of implement that a police officer believed could inflict harm.</h4>
<ol start="4" style="list-style-type: lower-alpha">
<li>What are three weapons that you are surprised to find in the “armed” variable? Make a table of the values in “armed” to see the options.</li>
</ol>
<pre class="r"><code>armed.val &lt;- table(unique(dat$armed))
View(armed.val)</code></pre>
<pre><code>## Warning in system2(&quot;/usr/bin/otool&quot;, c(&quot;-L&quot;, shQuote(DSO)), stdout = TRUE):
## running command &#39;&#39;/usr/bin/otool&#39; -L &#39;/Library/Frameworks/R.framework/
## Resources/modules/R_de.so&#39;&#39; had status 1</code></pre>
</div>
<div id="samurai-sword-is-very-unique-and-i-didnt-expect-to-see-that-in-there.-also-someone-must-have-very-good-dexterity-to-use-a-pen-in-a-dangerous-way.-i-also-found-the-specification-between-just-a-bb-gun-and-the-bb-gun-and-vehicle-option-interesting." class="section level4">
<h4>Samurai sword is very unique, and I didn’t expect to see that in there. Also, someone must have very good dexterity to use a pen in a dangerous way. I also found the specification between just a BB gun and the “BB gun and vehicle” option interesting.</h4>
</div>
</div>
<div id="problem-2-10-points" class="section level2">
<h2>Problem 2 (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>Describe the age distribution of the sample. Is this what you would expect to see?</li>
</ol>
<pre class="r"><code>hist(dat$age,
     main = &quot;Histogram of Age&quot;,
     xlim = c(0, 100),
     ylim = c(0, 1000),
     xlab = &quot;Ages&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<div id="the-age-distribution-of-the-sample-does-not-follow-a-normal-distribution-and-is-actually-skewed-right.-this-shows-us-that-more-victims-are-in-that-20-40-age-range.-this-makes-sense-to-me-intuitively-because-i-would-expect-victims-to-be-on-the-younger-side.-we-see-this-database-much-resembles-the-case-of-michael-brown-who-was-18-when-he-was-fatally-killed-by-an-officer-in-the-line-of-duty.-also-since-were-considering-fleeing-and-victims-with-weapons-i-would-expect-younger-people-to-be-more-stealthy-of-movers-and-quicker-with-weapons-since-old-people-dont-move-as-well." class="section level4">
<h4>The age distribution of the sample does not follow a normal distribution, and is actually skewed right. This shows us that more victims are in that 20-40 age range. This makes sense to me intuitively, because I would expect victims to be on the younger side. We see this database much resembles the case of Michael Brown, who was 18 when he was fatally killed by an officer in the line of duty. Also, since we’re considering “fleeing” and victims with weapons, I would expect younger people to be more stealthy of movers and quicker with weapons, since old people don’t move as well.</h4>
<ol start="2" style="list-style-type: lower-alpha">
<li>To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.</li>
</ol>
<pre class="r"><code>median(dat$age, na.rm = T)</code></pre>
<pre><code>## [1] 35</code></pre>
</div>
<div id="while-the-mean-would-represent-the-average-age-of-the-victims-in-the-dataset-the-median-actually-helps-us-find-the-middle-number-so-the-center-of-the-distribution.-we-can-see-here-that-the-median-is-35-years-of-age-which-falls-into-that-20-40-bucket-of-most-common-ages-in-part-a." class="section level4">
<h4>While the mean would represent the average age of the victims in the dataset, the median actually helps us find the middle number, so the “center” of the distribution. We can see here that the median is 35 years of age, which falls into that 20-40 bucket of most common ages in part a.</h4>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe the gender distribution of the sample. Do you find this surprising?</li>
</ol>
<pre class="r"><code>length(dat$gender[dat$gender == &quot;M&quot;])</code></pre>
<pre><code>## [1] 6301</code></pre>
<pre class="r"><code>length(dat$gender[dat$gender == &quot;F&quot;])</code></pre>
<pre><code>## [1] 296</code></pre>
<pre class="r"><code>length(dat$gender[dat$gender == &quot;None&quot;])</code></pre>
<pre><code>## [1] 3</code></pre>
</div>
<div id="nearly-all-the-victims-in-the-sample-were-men.-i-do-not-find-this-surprising-because-most-of-the-publicized-police-brutality-victims-trayvon-martin-george-floyd-michael-brown-etc.-have-been-men.-in-fact-im-not-sure-if-i-can-recall-an-incident-of-a-fatal-police-shooting-where-the-victim-was-a-woman-off-the-top-of-my-head.-also-it-could-be-that-gender-rolesstereotypes-play-into-how-aggressively-a-police-officer-treats-someone-which-is-why-more-men-are-killed-in-fatal-police-shootings." class="section level4">
<h4>Nearly all the victims in the sample were men. I do not find this surprising, because most of the publicized police-brutality victims (Trayvon Martin, George Floyd, Michael Brown, etc.) have been men. In fact, I’m not sure if I can recall an incident of a fatal police shooting where the victim was a woman off the top of my head. Also, it could be that gender roles/stereotypes play into how aggressively a police officer treats someone, which is why more men are killed in fatal police shootings.</h4>
</div>
</div>
<div id="problem-3-10-points" class="section level2">
<h2>Problem 3 (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?</li>
</ol>
<pre class="r"><code>body.cam.yes &lt;- length(which(dat$body_camera == &quot;TRUE&quot;))
(body.cam.yes/nrow(dat)) * 100</code></pre>
<pre><code>## [1] 13.80042</code></pre>
<div id="officers-had-a-body-camera.-im-surprised-by-how-low-this-proportion-is.-i-dont-know-much-about-body-camera-usage-by-officers-but-i-assumed-that-at-least-half-the-time-theres-an-incident-with-a-civilian-the-officer-would-turn-on-their-body-camerahave-some-kind-of-footage-at-some-point-during-the-encounter.-again-i-dont-know-the-requirements-for-body-cameras-but-i-expected-higher.-in-highly-publicized-cases-there-tends-to-be-body-camera-footage-perhaps-this-is-why-they-recieve-more-media-attention-so-i-just-assumed-that-would-be-very-common-and-not-only-occur-13-of-the-time." class="section level4">
<h4>910 officers had a body camera. I’m surprised by how low this proportion is. I don’t know much about body camera usage by officers, but I assumed that at least half the time there’s an incident with a civilian, the officer would turn on their body camera/have some kind of footage at some point during the encounter. Again, I don’t know the requirements for body cameras, but I expected higher. In highly publicized cases, there tends to be body camera footage (perhaps this is why they recieve more media attention), so I just assumed that would be very common, and not only occur 13% of the time.</h4>
<ol start="2" style="list-style-type: lower-alpha">
<li>In how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?</li>
</ol>
<pre class="r"><code>fleeing &lt;- length(which(dat$flee != &quot;Not fleeing&quot;))
(fleeing/nrow(dat)) * 100</code></pre>
<pre><code>## [1] 32.62056</code></pre>
</div>
<div id="victims-were-fleeing.-this-represents-about-a-third-of-the-total-number-of-incidents.-this-is-honestly-lower-than-what-i-expected.-again-i-dont-know-much-about-how-frequently-civilians-tend-to-flee-from-police-but-i-assumed-that-since-these-officers-used-fatal-violent-force-on-victims-these-victims-had-to-be-doing-something-such-as-fleeing-for-them-to-be-shot." class="section level4">
<h4>2151 victims were fleeing. This represents about a third of the total number of incidents. This is honestly lower than what I expected. Again, I don’t know much about how frequently civilians tend to flee from police, but I assumed that since these officers used (fatal) violent force on victims, these victims had to be doing something (such as fleeing), for them to be shot.</h4>
</div>
</div>
<div id="problem-4-10-points---answer-only-one-of-these-a-or-b." class="section level2">
<h2>Problem 4 (10 points) - Answer only one of these (a or b).</h2>
<ol style="list-style-type: lower-alpha">
<li>Describe the relationship between the variables “body camera” and “flee” using a stacked barplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the options for “flee”, each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<pre class="r"><code>tab.fleecam &lt;- table(dat$body_camera, dat$flee)
barplot(tab.fleecam,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Fleeing category&quot;, 
        ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.fleecam),
        beside = FALSE) </code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<div id="we-can-see-from-this-stacked-barplot-that-there-is-very-little-body-camera-footage-when-victims-are-fleeingnot-regardless.-additionally-there-is-actually-less-body-camera-footage-of-victims-who-were-fleeing-than-those-who-werent.-this-shocks-me-because-i-expect-police-would-turn-on-body-cameras-if-a-civilian-is-literally-moving-away-from-them.-i-expected-there-to-be-less-body-camera-footage-of-non-fleeing-victims-rather-than-the-opposite." class="section level4">
<h4>We can see from this stacked barplot that there is very little body camera footage when victims are fleeing/not regardless. Additionally, there is actually less body camera footage of victims who were fleeing than those who weren’t. This shocks me, because I expect police would turn on body cameras if a civilian is literally moving away from them. I expected there to be less body camera footage of non-fleeing victims, rather than the opposite.</h4>
<ol start="2" style="list-style-type: lower-alpha">
<li>Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<pre class="r"><code>plot(factor(dat$race), 
     dat$age, 
     ylab=&quot;Age&quot;, 
     xlab=&quot;Race&quot;,
     main = &quot;Boxplot of Age and Race&quot;)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
</div>
<div id="we-can-see-here-that-the-median-middle-age-of-white-and-asian-victims-is-higher-than-that-of-others.-we-can-also-see-that-black-victims-and-other-tend-to-have-the-lowest-ages.-also-we-can-see-the-age-range-of-white-victims-is-lowest.-we-can-see-here-that-members-of-certain-racial-categories-are-fatally-shot-at-younger-ages-than-those-of-others.-could-this-tie-into-life-expectancy-for-people-in-certain-racial-categories-people-of-white-and-asian-decent-have-higher-life-expectancies-than-say-black-people." class="section level4">
<h4>We can see here that the median (middle) age of White and Asian victims is higher than that of others. We can also see that Black victims (and other) tend to have the lowest ages. Also, we can see the age range of White victims is lowest. We can see here that members of certain racial categories are fatally shot at younger ages than those of others. Could this tie into life-expectancy for people in certain racial categories? People of White and Asian decent have higher life-expectancies, than say, Black people.</h4>
</div>
</div>
<div id="extra-credit-10-points" class="section level2">
<h2>Extra credit (10 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>What does this code tell us?</li>
</ol>
<pre class="r"><code>mydates &lt;- as.Date(dat$date)
head(mydates)
(mydates[length(mydates)] - mydates[1])</code></pre>
<div id="the-first-line-puts-the-date-variable-into-actual-date-form-r-initially-puts-them-in-as-characters.-we-can-see-that-now-all-the-dates-read-as-such-by-using-the-head-function.-the-last-line-calculates-the-time-difference-between-the-dates-and-shows-us-that-this-dataset-covers-2458-days-where-there-were-fatal-plicecivilian-shootings-thus-far.-this-is-over-6-years-of-time-which-means-that-this-dataset-must-have-been-updated-recently-since-it-first-started-in-2015-and-its-now-2021." class="section level4">
<h4>The first line puts the date variable into actual date form (R initially puts them in as characters). We can see that now all the dates read as such by using the head function. The last line calculates the time difference between the dates, and shows us that this dataset covers 2458 days where there were fatal plice/civilian shootings thus far. This is over 6 years of time, which means that this dataset must have been updated recently, since it first started in 2015 and it’s now 2021.</h4>
<ol start="2" style="list-style-type: lower-alpha">
<li>On Friday, a new report was published that was described as follows by The Guardian: “More than half of US police killings are mislabelled or not reported, study finds.” Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?</li>
</ol>
<p>I agree with this statement. We read in the codebook that the FBI/CDC log fatal shootings by police, but officials acknowledge that their data is incomplete. Since 2015, The Post has documented more than twice as many fatal shootings by police as recorded on average annually. I think perhaps this occurs because: paperwork isn’t done/finalized, trials are still occurring, details of cases are still emerging, and that it looks bad on the US that officials are shooting so many civilians.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Regarding missing values in problem 4, do you see any? If so, do you think that’s all that’s missing from the data?</li>
</ol>
<p>Yes, there are missing values in problem 4. I’m sure there are many other things that are missing from the data. All these events are unique of eachother and it’s hard to do EDA when there are so many specific values/cases, and its easier to put them all in an Other bucket.</p>
<p><span class="math display">\[\\[2in]\]</span></p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
</div>
</div>
<div id="exam-2" class="section level1">
<h1>Exam 2</h1>
<div id="instructions-1" class="section level2">
<h2>Instructions</h2>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.</p></li>
<li>Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: <strong>“Does having more funding in a police department lead to fewer incidents of police brutality?”</strong></li>
<li>Codebook:</li>
</ol>
<ul>
<li>funds: How much funding the police department received in that year in millions of dollars.</li>
<li>po.brut: How many incidents of police brutality were reported by the department that year.</li>
<li>po.dept.code: Police department code</li>
</ul>
</div>
<div id="problem-1-eda-10-points" class="section level2">
<h2>Problem 1: EDA (10 points)</h2>
<p>Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.</p>
<pre class="r"><code>## setwd(&quot;~/Desktop/senior year/crim 250/exam 2&quot;)
library(readr)
library(knitr)
library(ggpubr)
dat &lt;- read.csv(file = &#39;sim.data.csv&#39;)
dim(dat)</code></pre>
<pre><code>## [1] 200   3</code></pre>
<pre class="r"><code>length(unique(dat$po.brut))</code></pre>
<pre><code>## [1] 27</code></pre>
<pre class="r"><code>summary(dat$funds)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   21.40   51.67   59.75   61.04   72.17   99.70</code></pre>
<pre class="r"><code>summary(dat$po.brut)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   14.00   19.00   18.14   22.00   29.00</code></pre>
<p><strong>The dataset has 3 columns and 200 rows - each row represents a unique police department, and the three columns label these departments and acknowledge their funding/number of police brutality incidents. There are 27 different amounts of police brutality incidents. The summary functions show us the spread of the data for our two variables of interest - the median number of police brutaility incidents is 19 with a range of 14-29 incidents. It’s wild to me that at each department has at least 14 incidents in one year. The spread of funding is also interesting, because it differs in about $40Million, and the sheer amount is just so huge. The fact that half these departments recieve almost $60Million a year is crazy, but I also don’t know how big the towns/cities are in this dataset.</strong></p>
</div>
<div id="problem-2-linear-regression-30-points" class="section level2">
<h2>Problem 2: Linear regression (30 points)</h2>
<ol style="list-style-type: lower-alpha">
<li>Perform a simple linear regression to answer the question of interest. To do this, name your linear model “reg.output” and write the summary of the regression by using “summary(reg.output)”.</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
reg.output &lt;- lm(dat$po.brut ~ dat$funds) 
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$po.brut ~ dat$funds)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9433 -0.2233  0.2544  0.5952  1.1803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.543069   0.282503  143.51   &lt;2e-16 ***
## dat$funds   -0.367099   0.004496  -81.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9464 on 198 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.971 
## F-statistic:  6666 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>I am looking at how an increase of funds effects the number of police brutality incidents. I would expect that areas with higher levels of funding would have less incidents because they are probably in more well-to-do areas. Our intercept shows a negative correlation between funds and levels of incidents. This is similar to what I assumed, because as funding increases by one unit ($1Million), a police brutality incident is less likely to occur by 0.367099 unit. It would be interesting to use a log-linear relationship for this regression for an expected percent change in police brutality with each $1Million increase in funding.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.</li>
</ol>
<p><strong>The estimated coefficient of the intercept is 40.543069, the standard error is 0.282503, and the p-value is &lt;2e-16. The relationship between funds and incidents is statistically significant because 2e-16 &lt; .05, so we are able to reject the null hypothesis using our p-value. </strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:</li>
</ol>
<pre class="r"><code>ggscatter(dat, x = &quot;funds&quot;, y = &quot;po.brut&quot;, 
          add = &quot;reg.line&quot;, cor.method = &quot;pearson&quot;,
          xlab = &quot;Police Funding (in Millions of Dollars)&quot;, 
          ylab = &quot;Number of Police Brutality Incidents&quot;, 
          main = &quot;Relationship Between Funding and Brutality in Policing&quot;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-58-1.png" width="384" /></p>
<pre class="r"><code>## I used ggscatter because I am more familiar with the funciton, and a line of best fit/regression type can be specified within the function.</code></pre>
<p>Does the line look like a good fit? Why or why not?</p>
<p><strong>Yes, this line looks like a good fit. The scatter is a bit wacky since number of incidents only follows whole numbers and the regression does not output that (hence why I mention a log-linear regression above). Our line of best fit follows the regression output linearly, and does a pretty good job, but our scatter seems to resemble part of a parabolic function, so perhaps a exponentional regression would do the data more justice. I also did not run a fitted model.</strong></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?</li>
</ol>
<pre class="r"><code>reg.output &lt;- lm(dat$po.brut ~ dat$funds) 
plot(reg.output, which=1) ## linearity (residuals vs fitted)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<pre class="r"><code>plot(reg.output, which=3) ## equal variance (scale vs location)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-2.png" width="672" /></p>
<pre class="r"><code>plot(reg.output, which=2) ## normal pop. (qq)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-59-3.png" width="672" /></p>
<p><strong>Right off the bat I can see from the residuals vs fitted graph that the red line follows a trend in the average value of the residuals, so there is a discernable trend to them - this assumption fails. The independence assumption also fails due to the pattern of the residuals vs fitted graph. With the scale-location plot we see significant trends in the red line on this plot. This tells me that the residuals (and hence errors) have non-constant variance. So, the assumption that all the errors have the same variance is not true. The QQ plot shows that there is a left-skew to the data, and so the normality assumption fails. The assumptions of linearity are not satisfied, as I predicted above. With more time, I would hope for a better dataset so there is no omitted-variable bias (and the error estimates may be constant). Also, I would write a quadratic log-linear OLS regression, because that seems to better fit the data. For example, perhaps a quadratic on funds can also account for denser populated areas having more funds because of such, but also more incidents because they’re cities.</strong></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Answer the question of interest based on your analysis.</li>
</ol>
<p><strong>There is a statistically significant relationship between the two variables based on our summary of regression output. The ggscatter output shows this. It also tells us that increasing police funding would decrease the number of police-brutality incidents, and I suppose supports the argument to add more funding to the police. It’s important to remember that this is base on correlation, not causation, so adding more funding doesn’t necessarily “cause” a decrease in brutality incidents. Also, a linear model is not the best approach to comprehending our data, and so this regression isn’t the approach a statistician should take.</strong></p>
</div>
<div id="problem-3-data-ethics-10-points" class="section level2">
<h2>Problem 3: Data ethics (10 points)</h2>
<p>Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?</p>
<p><strong>I’m not sure if the anonymity of the police department names are enough. It’s very easy to look up police records/court cases regarding police brutality, so those numbers can be picked out. Also, as civically engaged members of society, we are able to look up public information on how our tax dollars are spent. So, finding the information on police department funding is also not difficult. If you looked at that and number of incidents, it’s not too difficult to find out which actual police department each number represents. There also may be bias in police-recorded data, because departments probably don’t want to admit that one of their own inflicted violence on a person. I also have concerns that people will use this data to predict police-brutality incidents, and will argue to change dpeartment funding because of such, and also as an argument that police-brutality happens normally, since each department had at least 14 incidents in one year. </strong></p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
